{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert title here\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Junhui Wen\n",
    "- Huiyi He\n",
    "- Xinyi(Cindy) Wang\n",
    "- Demi Mao\n",
    "- Jiayi Zhu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "Mobile devices have become a central part of people’s everyday lives, so it is necessary for mobile companies to understand the needs and requirements of their customers. Thus, our primary objective is to predict the price range of mobile phones given some information about a mobile phone such as battery power, clock speed, and RAM. The data we found is collected from different mobile phone companies on Kaggle. Each observation records some basic information about a phone without directly telling its model.\n",
    "\n",
    "We will do some data wrangling to remove null values, if there are some. Then, we will convert them to the right type for analysis. After that, we will perform exploratory data analysis to identify patterns and gain insights for modeling. Then we split the data into a training and testing set, select an appropriate machine learning algorithm and train on the training set. Finally, we deploy the model to make predictions on the test set. We will first measure the performance of our classifier by the accuracy/error rate. We also want to pay attention to the F1-score, which tells whether we have a balanced measure of precision and recall. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Since the last decade, the telecommunication industry has experienced great revolutions as mobile devices have become part of people’s everyday lives. With about 100 million mobile phone sales per year, the success of the mobile industry is highly dependent on its consumers<a name=\"sell_data\"></a>[<sup>[1]</sup>](#sell_data). Thus, the need and satisfaction of the user should be carefully considered when designing mobile devices and deciding the price. According to a publication of user experiences in mobile phones, by examining the correlation between several features and applying multiple regression, the size and color depth of the color screen, and the speed of webrosing of wireless connectivity are the one that is mostly related to the user satisfaction. The research paper also indicates that the presence of the camera does not affect the user's satisfaction level. However, since the study was conducted in 2006, and the technology for most camera phones were not mature enough at that time, the picture quality might be really bad, so the camera of the phone is not actually used by the user<a name=\"Ling\"></a>[<sup>[3]</sup>](#Ling). However there is no recent research on the effectiveness of mobile phones on user preference. \n",
    "\n",
    "In addition to basic understanding of how the features of the mobile phone affect the user's choices, there are research papers focusing on classifying mobile phone prices based on four physical features of the mobile phone: random accessing memory, the power of the battery, and the width and height of px. Among all four machine learning algorithms: Support Vector Machines, Decision Tree, K-Nearest Neighbor, and Naive Bayes Classification. The Support Vector Machines have the highest performance based on the standard performance matrix of accuracy, precision, recall, and F1 score with and without feature selection<a name=\"Hu\"></a>[<sup>[2]</sup>](#Hu), and the accuracy for SVM is 94.8 without feature selection and 97.7 with feature selection. In the same year 2022, another paper on classification on the price range of the mobile phone tested decision tree, random forest, and hybrid enable model of five different heterogeneous weak models was used and got respective results 85%, 91% and 96%. This provides us with some prior knowledge on algorithm selection and understanding <a name=\"Sakib\"></a>[<sup>[4]</sup>](#Sakib)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The problem we aim to address is to accurately predict mobile phone price ranges (represented by 0 to 4, which refers to the low price level, median price level, high price level and very high price level according to the aveage pricing of the current market) based on product characteristics, including battery power, clock speed, and RAM. Since our dataset has multiple features, one potential solution is random forest. Our problem is quantifiable as the phone features in the dataset can be represented as numerical data points, and the price range can be categorized into several different classes, making the problem expressible in mathematical terms. Moreover, the problem is measurable. The accuracy serves as a clear metric to evaluate the model. Metrics such as accuracy, precision, recall, and the F1-score can be used to assess our predictions. Finally, our problem is replicable. Our problem is based on a dataset that contains diverse phone models from various companies. As long as we have necessary features of the mobile phone, we can apply our model to predict the price range."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The dataset we will be using for this task is accessible via the following link: https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification?select=train.csv\n",
    "The dataset contains 21 variables, 1000 observations. Each observation contains information regarding the mobile phone's ID, battery power, Bluetooth capability, clock speed, dual SIM functionality, front camera megapixels (fc), 4G compatibility, internal memory, mobile depth (m_dep), mobile weight (mobile_wt), among other features.\n",
    "Before applying our Random Forest model, we will perform a thorough data cleaning and transformation process. Initially, we will check for missing values and decide whether to remove or impute the corresponding rows or columns based on the extent and nature of these missing values. We will also handle any incorrect values or outliers present in the dataset, taking care to ensure that the integrity of the data is maintained.\n",
    "Lastly, during the data transformation phase, we will examine the distribution of our data. If we find that our data is skewed, we might consider applying certain transformations, such as square root transformations, to create a more normally distributed dataset. \n",
    "\n",
    "Critical variables:\n",
    "`battery_power`: total energy a battery can store in one time measured in mAh. This is an integer in range 500 to 1999\n",
    "`blue`: has bluetooth or not. It’s represented by 1 (has bluetooth) or 0 (doesn’t have bluetooth)\n",
    "`clock_speed`: speed at which a microprocessor executes instructions. This is a decimal number between 0.5 and 3\n",
    "`dual_sim`: has dual sim support or not. It's represented by 1 (supports dual sim) and 0 (does not support dual sim).\n",
    "`int_memory`: internal memory in gigabytes. It’s represented by an integer in range 2 to 64."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "We will split the whole dataset into a train and test set. Within the training set, we further take some proportion out for the purpose of validation. While training the model using Random Forest, we will use k-fold cross validation and gridsearch to find the best parameter in order to find the best parameter. Then, we evaluate the best model on the testing set by metrics like accuracy and F1-score. After this, we will finally do a feature importance analysis to see which features are most influential in determining the price range. \n",
    "\n",
    "This solution would work because random forest can handle a large number of complex features compared to simple models like SVM. Also, random forest is very robust to outliers and unimportant features, so it should be a very good algorithm for the given problem.\n",
    "\n",
    "We will be comparing our model with the SVM model mentioned in the paper<a name=\"bg3\"></a>[<sup>[3]</sup>](#bg3note)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "To evaluate the performance of our prediction model, we will look at the accuracy and F1 values. Accuracy will show us the correctly predicted instances’ proportion to the total number of instances. F1 reflects the balance between precision and recall. A larger F1 score indicates a good trade-off between precision and recall and also represents a higher overall performance of a classification model. \n",
    "\n",
    "To calculate them, we need the values of True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN). The formula for accuracy is (TP + TN) / (TP + TN + FP + FN). The formula for the F1 score is (2 * Precision * Recall) / (Precision + Recall), also known as (2 * TP) / (2TP + FP + FN). \n",
    "\n",
    "The reason we look at accuracy and F1 is that they provide complementary information about the predictor model’s performance to mobile phone price, which gives the mobile phone company insights to set prices for their products. \n",
    "\n",
    "Updated from proposal feadback:\n",
    "\n",
    "In addition to the cofusion matrix of precision, recall, and F1, we will also add in the Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) based on the differences between predicted values and actual values. Since there are 4 labels from 0 to 3 with different price range for the predicted result, differences between 0 and 1 in the real prices is smaller than differences between 0 to 3 in the real prices. Thus, we will also consider the RMSE and MAE to quantify how far away our prediction deviated from the real value. The formula of a RMSE = sqrt(sum(actual result - predicted result)^2 / number of samples), and the formula of MAE is abs(acutal result - predicted result)/ number of samples. Our ultimate goal is to find a model that minimize the RMSE and MAE as well as maintain a relatively low F1 score. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For Modeling selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are total of 21 varaibles, with the first 20 varaibles representing the features of the mobile phones and the last varaible representing the label of the price range as explained in the data section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows with same values of features and with null value in any of the columns\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the features names for the future use\n",
    "feature_names = df.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.to_numpy()[:,:-1]\n",
    "y = df.to_numpy()[:,-1]\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Split the training set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [5, 7, 10],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_['params'] )\n",
    "results['accuracy'] = grid_search.cv_results_['mean_test_score']\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print the best prarameter\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the explaination above, the best hyper-parameters for the random forest classifier based on the grid search is: the maximum depth of the tree is 15, the number is the features taking into account for each decision tree is the square root of all features which is approximatly sqrt(20), the minimum number of sample required to split the node further is 10, and the number of trees in the forest is 150. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visulizing the first 3 decision trees of the best_model\n",
    "for i in range(3):\n",
    "    tree = best_model.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=feature_names,  \n",
    "                               filled=True,\n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to analysis the how important each features contribute to the overall performance of the random forest. The following two plots shows the calculated feature importances based on the mean decrease in impurity value and the decrease in the model score which is more rebust to the cardinality of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the feature importances using impurity\n",
    "importances = best_model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in best_model.estimators_], axis=0)\n",
    "forest_importances1 = pd.Series(importances, index=feature_names)\n",
    "\n",
    "# Calculating the feature importances using permutation of features and overall model score\n",
    "result = permutation_importance(\n",
    "    best_model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "forest_importances2 = pd.Series(result.importances_mean, index=feature_names)\n",
    "fig, axs = plt.subplots(2)\n",
    "\n",
    "forest_importances1.plot.bar(yerr=std, ax=axs[0])\n",
    "axs[0].set_title(\"Feature importances using MDI\")\n",
    "axs[0].set_ylabel(\"Mean decrease in impurity\")\n",
    "\n",
    "forest_importances2.plot.bar(yerr=result.importances_std, ax=axs[1])\n",
    "axs[1].set_title(\"Feature importances using permutation on full model\")\n",
    "axs[1].set_ylabel(\"Mean accuracy decrease\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important features based on both plots are: \n",
    "1. random accessing memory, and \n",
    "2. battery_power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 1) add F1 score (and maybe other evaluation metrics)\n",
    "#       2) feature importances analysis [DONE]\n",
    "#       3) add more explanation for code above [DONE]\n",
    "#       4) consider strategies that make the training process less biased toward continuous variables (like RAM)\n",
    "#       5) copy-and-paste sections from proposal to here [DONE]\n",
    "#       6) show some decision trees of the best parameters [DONE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
